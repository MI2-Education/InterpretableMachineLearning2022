{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5ea4866",
   "metadata": {},
   "source": [
    "# Metoda CP\n",
    "## Opis danych\n",
    "Dane pochodzą z bazy o nazwie TUH Abnormal EEG Corpus (https://isip.piconepress.com/projects/tuh_eeg/downloads/tuh_eeg_abnormal/v2.0.0/). Są to zapisy sygnału EEG z jednego szpitala sklasyfikowane jako prawidłowe lub nieprawidłowe.\n",
    "\n",
    "## Podstawowe informacje ułatwiające dalsze zrozumienie:\n",
    "Do badania użyto standardowego układu elektrod 10-20, wygląda on następująco:\n",
    "\n",
    "<p><IMG src=\"img/10-20.png\" width=500></p>\n",
    "\n",
    "Do każdego sygnału EEG jest załączony opis lekarza, który nie zawsze używa konkretnych nazw elektrod, tylko bardziej ogólne określenia.\n",
    "\n",
    "* Parzyste numery elektrod są po prawej stronie, nieparzyste - po lewej\n",
    "* Geneza literek w nazwach: pre-frontal (Fp), frontal (F), temporal (T), parietal (P), occipital (O), central (C)\n",
    "* Zwolnienia w obszarach mózgu, K kompleksy - niskie częstotliwości\n",
    "* Vertex, sharp waves - wyższe częstotliwości\n",
    "* Wrzeciona snu (spindles) 12-16 Hz\n",
    "    \n",
    "## Drzewo decyzyjne\n",
    "### Wybór cech\n",
    "Lekarze oceniali sygnały EEG używając jedynie oczu i linijek - skupiali się więc na mocy danych częstotliwości w danych kanałach. Aby móc porównywać moje wyjaśnienia z ich opisami, wybrałam te same cechy. Dla każdego kanału obliczyłam moc sygnału w następujących pasmach częstotliwości:\n",
    "\n",
    "* 0-2 Hz (delta)\n",
    "* 1-3 Hz (delta)\n",
    "* 2-4 Hz (delta)\n",
    "* 3-6 Hz (theta)\n",
    "* 4-8 Hz (theta)\n",
    "* 6-10 Hz (alfa)\n",
    "* 8-13 Hz (alfa)\n",
    "* 10-15 Hz (beta)\n",
    "* 13-18 Hz (beta)\n",
    "* 15-21 Hz (beta)\n",
    "* 18-24 Hz (beta)\n",
    "* 21-27 Hz (beta)\n",
    "* 24-30 Hz (gamma)\n",
    "* 27-39 Hz (gamma)\n",
    "* 30-49 Hz (gamma)\n",
    "Uzyskałam w ten sposób 15x21=315 cech. Nie stosowałam żadnych redukcji cech, ponieważ chciałam uzyskać pełen obraz dla wszystkich cech.\n",
    "\n",
    "Wyniki modelu na zbiorze ewaluacyjnym\n",
    "* ACC - 0.84\n",
    "* MCC - 0.67\n",
    "* Spec - 0.87\n",
    "* Sens - 0.85\n",
    "### Wyjaśnianie konkretnych przypadków:\n",
    "    \n",
    "#### Przypadek pierwszy, klasyfikator poprawnie stwierdził nieprawidłowość EEG.\n",
    "* Fragment opisu lekarza: \"Abnormal EEG due to replacement of normal background primarily with a beta frequency pattern, superimposed asymmetry with relatively less beta and more suppression in the left particularly in the posterior quadrant\"\n",
    "* Rysunek przedstawiający wpływ zmienności wybranych cech:\n",
    "    \n",
    "<IMG src=\"img/sub_00007383_073.png\">   \n",
    "    \n",
    "Akurat ta metoda wyjaśniania modelu dla patologicznych sygnałów EEG może być mało skuteczna, ponieważ nigdy w mózgu nie będzie sytuacji że tylko dla jednego kanału i jednego pasma sygnał będzie patologiczny. Jest to spowodowane tym że jednak mózg to sieć połączeń nerwowych gdzie występuje dużo skomplikowanych zależności między kanałami. Jeżeli więc dla patologicznego przypadku manipulujemy jedną wartością, to pozostałe patologiczne wartości pozostają nadal patologiczne i model nadal pokazuje że sygnał jest patologiczny.\n",
    "    \n",
    "#### Przypadek drugi, klasyfikator poprawnie stwierdził nieprawidłowość EEG.\n",
    "\n",
    "* Rysunek przedstawiający wpływ zmienności wybranych cech których przebieg różni się od przypadku pierwszego: \n",
    "    \n",
    "<IMG src=\"img/sub_00006531_065.png\">   \n",
    "    \n",
    "Zmienności w przebiegach tych zależności nie da się jednoznacznie wytłumaczyć, ponieważ stan mózgu to całość na raz. Wystarczy więc że w jednym miejscu coś się zmieni, to inne kanały też powinny się dostosować do zmiany. W przypadku patologicznych zmian, te krzywe mogą być za każdym razem inne. \n",
    "    \n",
    "#### Przypadek trzeci, klasyfikator poprawnie stwierdził prawidłowość EEG.\n",
    "\n",
    "* Rysunek przedstawiający wpływ zmienności wybranych cech których przebieg różni się od przypadku pierwszego: \n",
    "    \n",
    "<IMG src=\"img/sub_00004586_045.png\">  \n",
    "    \n",
    "Jedynym przypadkiem gdzie można sprawdzić poprawność działania tej metody, jest analiza niepatologicznego EEG. Tutaj wyraźnie widać, że nasz przypadek jest w 'dołku' i jakiekolwiek odchylenia powodują wzrost prawdopodobieństwa że EEG jest patologiczne.\n",
    "\n",
    "## Sieć konwolucyjna   \n",
    "Jako drugi model wybrałam prostą sieć konwolucyjną, która na wejściu otrzymuje macierz tych samych danych co powyższy model, ale o kształcie (liczba_pasm x liczba_kanałów).\n",
    "\n",
    "### Wyniki modelu na zbiorze ewaluacyjnym:\n",
    "* ACC - 0.77\n",
    "    \n",
    "### Wyjaśnianie konkretnych przypadków (tych samych co dla Random Forest):\n",
    "    \n",
    "#### Przypadek pierwszy, klasyfikator poprawnie stwierdził nieprawidłowość EEG.\n",
    "* Fragment opisu lekarza: \"Abnormal EEG due to replacement of normal background primarily with a beta frequency pattern, superimposed asymmetry with relatively less beta and more suppression in the left particularly in the posterior quadrant\"\n",
    "* Rysunek przedstawiający wpływ zmienności wybranych cech:\n",
    "    \n",
    "<IMG src=\"img/sub_00007383_073_conv.png\">  \n",
    "    \n",
    "#### Przypadek drugi, klasyfikator poprawnie stwierdził prawidłowość EEG.\n",
    "* Rysunek przedstawiający wpływ zmienności wybranych cech:\n",
    "\n",
    "<IMG src=\"img/sub_00004586_045_conv.png\">     \n",
    "    \n",
    "Wydaje mi się że ta metoda nie sprawdziła się dla tego modelu. Wyniki są mniej jednoznaczne co znacznie utrudnia interpretacje. Może to wynikać z większej złożoności modelu i jednocześnie mniejszej wartości acc.\n",
    "    \n",
    "# Appendix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "126898f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dmj/fizmed/mpoziomska/.pyenv/versions/3.6.10/envs/HW1/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning:\n",
      "\n",
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import dalex as dx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from einops import rearrange\n",
    "from skimage import color\n",
    "from sklearn.svm import SVC\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import matthews_corrcoef, confusion_matrix, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a1f24aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_names = ['FP1', 'FP2', 'F3', 'F4', 'C3', 'C4', 'P3', 'P4', 'O1', 'O2', 'F7', \n",
    "            'F8', 'T3', 'T4', 'T5', 'T6', 'A1', 'A2', 'FZ', 'CZ', 'PZ']\n",
    "\n",
    "BAND_LIMITS = np.array([[ 0,  2, 'delta'],\n",
    "       [ 1,  3, 'delta'],\n",
    "       [ 2,  4, 'delta'],\n",
    "       [ 3,  6, 'theta'],\n",
    "       [ 4,  8, 'theta'],\n",
    "       [ 6, 10, 'alfa'],\n",
    "       [ 8, 13, 'alfa'],\n",
    "       [10, 15, 'beta'],\n",
    "       [13, 18, 'beta'],\n",
    "       [15, 21, 'beta'],\n",
    "       [18, 24, 'beta'],\n",
    "       [21, 27, 'beta'],\n",
    "       [24, 30, 'gamma'],\n",
    "       [27, 39, 'gamma'],\n",
    "       [30, 49, 'gamma']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6bb68ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('data/X_train.csv')\n",
    "Y_train = np.load('data/Y_train.npy')\n",
    "X_eval = pd.read_csv('data/X_eval.csv')\n",
    "Y_eval = np.load('data/Y_eval.npy')\n",
    "cols = np.array(X_eval.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74b88f6",
   "metadata": {},
   "source": [
    "# Model Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1c2001d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8369565217391305 0.671317113342619 0.8866666666666667 0.8521739130434782\n"
     ]
    }
   ],
   "source": [
    "clf_eval_rf = RandomForestClassifier(n_estimators=1600, max_depth=90, max_features=\"sqrt\", min_samples_split=2, random_state=4, \n",
    "                             criterion='entropy', n_jobs=20)\n",
    "clf_eval_rf.fit(X_train, Y_train)\n",
    "preds = clf_eval_rf.predict(X_eval)\n",
    "probs = clf_eval_rf.predict_proba(X_eval)\n",
    "acc_rf = accuracy_score(Y_eval, preds)\n",
    "mcc = matthews_corrcoef(Y_eval, preds)\n",
    "tn, fp, fn, tp = confusion_matrix(Y_eval, preds).ravel()\n",
    "spec = tn / (tn+fp)\n",
    "sens = tp / (tp + fp)\n",
    "print(acc_rf, mcc, spec, sens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50862c9",
   "metadata": {},
   "source": [
    "# Model sieci konwolucyjnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ed1bd13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_matrix(X):\n",
    "    X_net = np.zeros((len(X), 1, len(BAND_LIMITS), len(ch_names)))\n",
    "    for idx, sub in enumerate(X):\n",
    "        for idx_ch, ch in enumerate(ch_names):\n",
    "            for idx_b, [l, h, n] in enumerate(BAND_LIMITS):\n",
    "                name = f'ch_{ch}_{l}-{h} Hz ({n})'\n",
    "                X_net[idx, 0, idx_b, idx_ch] = sub[name == cols]\n",
    "        \n",
    "    return X_net.astype('float32')\n",
    "\n",
    "X_eval_mat = make_matrix(np.array(X_eval))\n",
    "X_train_mat = make_matrix(np.array(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "245e342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Shallow(nn.Module):\n",
    "    \n",
    "    def __init__(self, f1, f2):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1, f1, (3, 4))\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(f1, f2, (3, 4))\n",
    "        \n",
    "        self.avr = nn.AvgPool2d((3, 3), stride=(2, 2))\n",
    "        \n",
    "        self.lin = nn.Linear(int(350 * f2/10), 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #print(x.shape)\n",
    "        z = self.conv1(x)\n",
    "        #print(z.shape)\n",
    "        #print(z.shape)\n",
    "        z = self.conv2(z)\n",
    "        #print(z.shape)\n",
    "        z = torch.square(z)\n",
    "        #print(z.shape)\n",
    "        z = self.avr(z)\n",
    "        #print(z.shape)\n",
    "        z = torch.log(z)\n",
    "        z = rearrange(z, 'b c d e -> b (c d e)')\n",
    "        z = self.lin(z)\n",
    "        #print(z.shape)\n",
    "        \n",
    "        z = torch.sigmoid(z)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        return get_pred(self.predict_proba(X))\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        \n",
    "        #print(np.array(X).shape)\n",
    "        X = make_matrix(np.array(X))\n",
    "        \n",
    "        return self(torch.from_numpy(X)).cpu().detach().numpy().copy()[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2900007e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, time 0.00 min, ACC 0.71, loss 0.72\n",
      "Epoch 2, time 0.00 min, ACC 0.72, loss 0.60\n",
      "Epoch 3, time 0.00 min, ACC 0.74, loss 0.54\n",
      "Epoch 4, time 0.00 min, ACC 0.73, loss 0.52\n",
      "Epoch 5, time 0.00 min, ACC 0.73, loss 0.52\n",
      "Epoch 6, time 0.00 min, ACC 0.74, loss 0.51\n",
      "Epoch 7, time 0.00 min, ACC 0.75, loss 0.50\n",
      "Epoch 8, time 0.00 min, ACC 0.75, loss 0.50\n",
      "Epoch 9, time 0.00 min, ACC 0.75, loss 0.50\n",
      "Epoch 10, time 0.00 min, ACC 0.75, loss 0.50\n",
      "Epoch 11, time 0.00 min, ACC 0.75, loss 0.50\n",
      "Epoch 12, time 0.00 min, ACC 0.76, loss 0.50\n",
      "Epoch 13, time 0.00 min, ACC 0.76, loss 0.49\n",
      "Epoch 14, time 0.00 min, ACC 0.76, loss 0.49\n",
      "Epoch 15, time 0.00 min, ACC 0.76, loss 0.49\n",
      "Epoch 16, time 0.00 min, ACC 0.77, loss 0.49\n",
      "Finished, time 0.02 min\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate(Net, X_eval, probs, MCC, Loss, epoch, trloss, t0):\n",
    "\n",
    "    Net.eval()\n",
    "    j = 0\n",
    "    for i in range(len(X_eval_mat) // batch_size):\n",
    "        X = torch.from_numpy(X_eval_mat[i * batch_size : min((i + 1) * batch_size, len(Y_eval) - 1)])\n",
    "\n",
    "        X = X.to(device)\n",
    "\n",
    "        nt = len(X)\n",
    "        \n",
    "        out = Net(X)\n",
    "        probs[j:j+nt] = out.cpu().detach().numpy().copy()[:, 0]\n",
    "        j += nt\n",
    "\n",
    "    preds = get_pred(probs)\n",
    "    acc = accuracy_score(Y_eval, preds)\n",
    "\n",
    "    ACC[epoch-1] = acc\n",
    "    Loss[epoch-1] = trloss\n",
    "    print(f\"Epoch {epoch}, time {(time.time() - t0) / 60:.2f} min, ACC {acc:.2f}, loss {trloss:.2f}\")\n",
    "\n",
    "def get_pred(probs):\n",
    "\n",
    "    if np.sum(np.isnan(probs)) > 0:\n",
    "        raise Warning(\"Nan values in probs!\")\n",
    "    else:\n",
    "        return (probs.flatten() > 0.5) * 1\n",
    "\n",
    "epochs = 16\n",
    "batch_size = 64\n",
    "probs = np.zeros((len(X_eval)))\n",
    "ACC = np.zeros((epochs))\n",
    "Loss = ACC.copy()\n",
    "device = torch.device(\"cuda:0\" if not torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LOSS = nn.BCELoss()\n",
    "t0_mod = time.time()\n",
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "def run_net(f1, f2):\n",
    "    Net = Shallow(f1, f2)\n",
    "    Net.to(device)\n",
    "    optimizer = torch.optim.AdamW(Net.parameters())\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        t0_ep = time.time()\n",
    "\n",
    "        Net.train()\n",
    "        trloss = 0\n",
    "        for i in range(len(X_train_mat) // batch_size):\n",
    "            X = torch.from_numpy(X_train_mat[i * batch_size : min((i + 1) * batch_size, len(Y_train) - 1)])\n",
    "            y = torch.from_numpy(np.array([Y_train[i * batch_size : min((i + 1) * batch_size, len(Y_train) - 1)]]).T.astype('float32'))\n",
    "\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = Net(X)\n",
    "\n",
    "            loss = LOSS(out, y)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            trloss += loss.data.item() * len(X)\n",
    "\n",
    "        trloss /= len(X_train)\n",
    "\n",
    "        evaluate(Net, X_eval, probs, ACC, Loss, epoch, trloss, t0_ep)\n",
    "\n",
    "    print(f\"Finished, time {(time.time() - t0_mod) / 60:.2f} min\\n\")\n",
    "    return Net\n",
    "\n",
    "Net = run_net(7, 12)\n",
    "preds = get_pred(probs)\n",
    "acc_net = ACC[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382b9d6e",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf4ba0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8079710144927537"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_eval_svc = SVC(kernel=\"rbf\", C=10, probability=True, gamma=\"auto\")\n",
    "clf_eval_svc.fit(X_train, Y_train)\n",
    "preds = clf_eval_svc.predict(X_eval)\n",
    "acc_svc = accuracy_score(Y_eval, preds)\n",
    "acc_svc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1244e941",
   "metadata": {},
   "source": [
    "# Permutacje:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1e2df9",
   "metadata": {},
   "source": [
    "Funkcja dla tradycyjnej permutacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8fbc7860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trad_perm(n_perm, name, clf, acc):\n",
    "    n_feat = len(cols)\n",
    "    l = 0\n",
    "    T = np.zeros((n_feat, n_perm))\n",
    "    for idx_f, f in enumerate(cols):\n",
    "        for idx_p in range(n_perm):\n",
    "            t0 = time.time()\n",
    "            df = X_eval.copy()\n",
    "            df[f] = np.random.permutation(df[f])\n",
    "            preds2 = clf.predict(df)\n",
    "            T[idx_f, idx_p] = acc - accuracy_score(Y_eval, preds2)\n",
    "            l += 1\n",
    "            print(f\"{l} z {n_feat*n_perm}, {(time.time() - t0) / 60}\")\n",
    "\n",
    "    np.save(f'results2/{name}_trad.npy', T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcac19e0",
   "metadata": {},
   "source": [
    "Funkcja dla shapowej permutacji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2681a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_perm(n_perm, name, clf):\n",
    "    n_feat = len(cols)\n",
    "\n",
    "    T = np.zeros((n_feat, n_perm))\n",
    "    shuff_cols = cols.copy()\n",
    "\n",
    "    l = 0\n",
    "    for idx_f, f in enumerate(cols):\n",
    "        for idx_p in range(n_perm):\n",
    "\n",
    "            t0 = time.time()\n",
    "\n",
    "            df = X_eval.copy()\n",
    "            np.random.shuffle(shuff_cols)\n",
    "            idx_sh_f = np.argwhere(shuff_cols == f)[0, 0]\n",
    "            cols_bf = shuff_cols[:idx_sh_f]\n",
    "            for c in cols_bf:\n",
    "                df[c] = np.random.permutation(df[c])\n",
    "\n",
    "            preds_bf = clf.predict(df)\n",
    "            acc_bf = accuracy_score(Y_eval, preds_bf)\n",
    "\n",
    "\n",
    "            df[f] = np.random.permutation(df[f])\n",
    "\n",
    "            preds_af = clf.predict(df)\n",
    "            acc_af = accuracy_score(Y_eval, preds_af)\n",
    "\n",
    "            T[idx_f, idx_p] = acc_bf - acc_af\n",
    "\n",
    "            l += 1\n",
    "            print(f\"{l} z {n_feat*n_perm}, {(time.time() - t0) / 60}, {acc_bf}, {acc_af}, {acc_bf - acc_af}\")\n",
    "\n",
    "    np.save(f'results2/{name}_shap.npy', T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "965651b6",
   "metadata": {},
   "source": [
    "Permutowanie całych kanałów na raz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39e65d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shap_perm_chan(n_perm, name, clf, acc):\n",
    "    n_feat = len(ch_names)\n",
    "    c = 0\n",
    "    T = np.zeros((n_feat, n_perm))\n",
    "    for idx_ch, ch in enumerate(ch_names):\n",
    "        for idx_p in range(n_perm):\n",
    "            t0 = time.time()\n",
    "            df = X_eval.copy()\n",
    "            for idx_f, [l, h, n] in enumerate(BAND_LIMITS):\n",
    "                f = f'ch_{ch}_{l}-{h} Hz ({n})'\n",
    "                df[f] = np.random.permutation(df[f])\n",
    "            preds2 = clf.predict(df)\n",
    "            T[idx_f, idx_p] = acc - accuracy_score(Y_eval, preds2)\n",
    "            c += 1\n",
    "            print(f\"{c} z {n_feat*n_perm}, {(time.time() - t0) / 60}\")\n",
    "\n",
    "    np.save(f'results2/{name}_trad_chan.npy', T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfef799",
   "metadata": {},
   "source": [
    "Permutowanie całych częstotliwości na raz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "feacf2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trad_perm_freq(n_perm, name, clf, acc):\n",
    "    n_feat = len(BAND_LIMITS)\n",
    "    c = 0\n",
    "    T = np.zeros((n_feat, n_perm))\n",
    "    for idx_f, [l, h, n] in enumerate(BAND_LIMITS):\n",
    "        for idx_p in range(n_perm):\n",
    "            t0 = time.time()\n",
    "            df = X_eval.copy()\n",
    "            for idx_ch, ch in enumerate(ch_names):\n",
    "                f = f'ch_{ch}_{l}-{h} Hz ({n})'\n",
    "                df[f] = np.random.permutation(df[f])\n",
    "            preds2 = clf.predict(df)\n",
    "            T[idx_f, idx_p] = acc - accuracy_score(Y_eval, preds2)\n",
    "            c += 1\n",
    "            print(f\"{c} z {n_feat*n_perm}, {(time.time() - t0) / 60}\")\n",
    "\n",
    "    np.save(f'results2/{name}_trad_freq.npy', T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e73b26",
   "metadata": {},
   "source": [
    "Permutowanie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6163c2e2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap_perm_freq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/HW1/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m                 \u001b[0mtasks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready_batches\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    160\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEmpty\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-e40db43fe94b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m Parallel(n_jobs=3)(\n\u001b[0;32m---> 17\u001b[0;31m             delayed(shap_perm_freq) (n_perm, name, clf) for name, [clf, acc] in P.items())\n\u001b[0m\u001b[1;32m     18\u001b[0m Parallel(n_jobs=3)(\n\u001b[1;32m     19\u001b[0m             delayed(shap_perm_chan) (n_perm, name, clf) for name, [clf, acc] in P.items())\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/HW1/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;31m# remaining jobs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.10/envs/HW1/lib/python3.6/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    831\u001b[0m                 \u001b[0mbig_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m                 \u001b[0mislice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mislice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-e40db43fe94b>\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m Parallel(n_jobs=3)(\n\u001b[0;32m---> 17\u001b[0;31m             delayed(shap_perm_freq) (n_perm, name, clf) for name, [clf, acc] in P.items())\n\u001b[0m\u001b[1;32m     18\u001b[0m Parallel(n_jobs=3)(\n\u001b[1;32m     19\u001b[0m             delayed(shap_perm_chan) (n_perm, name, clf) for name, [clf, acc] in P.items())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shap_perm_freq' is not defined"
     ]
    }
   ],
   "source": [
    "P = {'conv': [Net, acc_net], 'rf': [clf_eval_rf, acc_rf], 'svc': [clf_eval_svc, acc_svc]}\n",
    "n_perm = 50\n",
    "\n",
    "'''Parallel(n_jobs=3)(\n",
    "            delayed(shap_perm) (n_perm, name, clf) for name, [clf, acc] in P.items())\n",
    "\n",
    "Parallel(n_jobs=3)(\n",
    "            delayed(trad_perm) (n_perm, name, clf, acc) for name, [clf, acc] in P.items())'''\n",
    "\n",
    "Parallel(n_jobs=3)(\n",
    "            delayed(trad_perm_freq) (n_perm, name, clf, acc) for name, [clf, acc] in P.items())\n",
    "\n",
    "Parallel(n_jobs=3)(\n",
    "            delayed(trad_perm_chan) (n_perm, name, clf, acc) for name, [clf, acc] in P.items())\n",
    "\n",
    "Parallel(n_jobs=3)(\n",
    "            delayed(shap_perm_freq) (n_perm, name, clf) for name, [clf, acc] in P.items())\n",
    "Parallel(n_jobs=3)(\n",
    "            delayed(shap_perm_chan) (n_perm, name, clf) for name, [clf, acc] in P.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad987ed8",
   "metadata": {},
   "source": [
    "Rysunki jako mapy cieplne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a2a66307",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_matrix(X, name):\n",
    "    sc = 1\n",
    "    print(name)\n",
    "    res_path = 'img/'\n",
    "    if np.sum(X < 0) == 0:\n",
    "        vmin = np.min(X)\n",
    "        vmax = np.max(X)\n",
    "        cmap = 'Reds'\n",
    "    else:\n",
    "        clim = np.max(np.abs(X))\n",
    "        vmin = -clim\n",
    "        vmax = clim\n",
    "        cmap = 'RdBu_r'\n",
    "    \n",
    "    plt.figure(figsize=(sc*12, sc*7.5))\n",
    "    plt.imshow(X, cmap = cmap, vmin = vmin, vmax = vmax)\n",
    "    plt.xticks(np.arange(0, len(ch_names)), ch_names, fontsize=12*sc)\n",
    "    plt.yticks(np.arange(0, len(BAND_LIMITS)), (f'{int(l)}-{int(h)} Hz ({n})' for l, h, n in BAND_LIMITS), fontsize=12*sc)\n",
    "    plt.xlabel(\"Kanały\", fontsize=15*sc)\n",
    "    plt.ylabel(\"Pasma mocy\", fontsize=15*sc)\n",
    "    plt.colorbar(fraction=0.03, pad=0.01)\n",
    "    plt.savefig(res_path + f'{name}.png')\n",
    "    plt.show()\n",
    "    \n",
    "def plot_row(X, name):\n",
    "    sc = 1\n",
    "    print(name)\n",
    "    res_path = 'img/'\n",
    "    if np.sum(X < 0) == 0:\n",
    "        vmin = np.min(X)\n",
    "        vmax = np.max(X)\n",
    "        cmap = 'Reds'\n",
    "    else:\n",
    "        clim = np.max(np.abs(X))\n",
    "        vmin = -clim\n",
    "        vmax = clim\n",
    "        cmap = 'RdBu_r'\n",
    "    \n",
    "    \n",
    "    X = X.reshape(1, len(X))\n",
    "    plt.figure(figsize=(sc*12, sc*7.5))\n",
    "    plt.imshow(X, cmap = cmap, vmin = vmin, vmax = vmax)\n",
    "    if 'chan' in name:\n",
    "        plt.xticks(np.arange(0, len(ch_names)), ch_names, fontsize=12*sc)\n",
    "        plt.xlabel(\"Kanały\", fontsize=15*sc)\n",
    "    else:\n",
    "        plt.xticks(np.arange(0, len(BAND_LIMITS)), (f'{int(l)}-{int(h)} Hz ({n})' for l, h, n in BAND_LIMITS), fontsize=12*sc, rotation=90)\n",
    "        plt.xlabel(\"Pasma mocy\", fontsize=15*sc)\n",
    "    plt.colorbar(fraction=0.03, pad=0.01)\n",
    "    plt.savefig(res_path + f'{name}.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1535daa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc_shap 0.028832817941786187\n",
      "conv_trad 0.011621062637659154\n",
      "rf_shap 0.015020945608493659\n",
      "conv_trad_freq 0.017948501560146136\n",
      "conv_shap 0.014959644306666449\n",
      "conv_trad_chan 0.003009646327144231\n",
      "rf_trad 0.004525360868404644\n",
      "rf_trad_freq 0.007025622981762785\n",
      "rf_trad_chan 0.004941370180067324\n",
      "svc_trad 0.010777082404156415\n",
      "svc_trad_freq 0.01805787796286538\n",
      "svc_trad_chan 0.010021243975318348\n"
     ]
    }
   ],
   "source": [
    "folder = 'results/'\n",
    "for f in os.listdir(folder):\n",
    "    if '.npy' in f:\n",
    "        X = np.load(folder + f)\n",
    "        name = f.replace('.npy', '')\n",
    "        print(name, np.max(np.std(X, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2b1e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
